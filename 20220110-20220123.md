
### 意见性分享

#### 图表绘制工具分享

[Keenan Crane](https://twitter.com/keenanisalive/status/1480696621298069506) recommend this :

Penrose: [UsePenrose](https://twitter.com/UsePenrose)

The whole system is open source, and (if you're brave!) you can run it yourself: https://github.com/penrose/penrose

#### DL architectures

[Taco Cohen](https://twitter.com/TacoCohen/status/1480855159236440066)

The first law of DL architectures:   "Whatever" is all you need. Any problem that can be solved by transformer / ViT can be solved by MLP / CNN, and vice versa (provided you do exhaustive tuning, and use the right inductive bias).  

Like [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)

Same for RNNs: [Capacity and Trainability in Recurrent Neural Networks](https://arxiv.org/abs/1611.09913)

#### paper writing

[Thomas G. Dietterich](https://twitter.com/tdietterich/status/1481023353322307585)
The term "ablation" is widely misused lately in ML papers. An ablation is a removal: you REMOVE some component of the system (e.g., remove batchnorm). A "sensitivity analysis" is where you VARY some component (e.g., network width).

[Jia-Bin Huang](https://twitter.com/jbhuang0604/status/1481821813093150728)

Unsolicited paper writing tip: 

Don’t claim “We are the FIRST to do…”

Found many papers falsely claimed it as a contribution. (You never knew what some researchers have done in the 90s!)

#### debate between ConvNets and Transformers

[Yann LeCun](https://twitter.com/ylecun/status/1481196571534536704)

ConvNeXt: the debate heats up between ConvNets and Transformers for vision!

Very nice work from FAIR+BAIR colleagues showing that with the right combination of methods, ConvNets are better than Transformers for vision. 87.1% top-1 ImageNet-1k.[ConvNet](https://arxiv.org/abs/2201.03545)

Some of the helpful tricks make complete sense: larger kernels, layer norm, fat layer inside residual blocks, one stage of non-linearity per residual block, separate downsampling layers....

Am I going to argue that "Conv is all you need"?
No!
My favorite architecture is DETR-like: ConvNet (or ConvNeXt) for the first layers, then something more memory-based and permutation invariant like transformer blocks for object-based reasoning on top.



### 课程和报告分享

[Maching-learning-book based on the Pytorch](https://twitter.com/rasbt/status/1480224660470083588)

[Great video on online presentation tips](https://twitter.com/CSProfKGD/status/1482162054114988037)

**Taichi's 2021**(https://twitter.com/TaichiGraphics/status/1481932497386881031): Find out how much progress this parallel programming language has made in terms of functionality, performance, application scenarios and our community

**[PlotNeuralNet](https://github.com/HarisIqbal88/PlotNeuralNet)**: Use LaTex for making neural networks diagrams!

**[PEPit](https://github.com/bgoujaud/PEPit)**: PEPit is a new Python package for computer-assisted worst-case analyses; Too busy/tired/lazy to find a convergence proof for your latest optimization algorithm? Let your computer do it!

#### [Hausdorff School](https://www.hcm.uni-bonn.de/events/eventpages/hausdorff-school/hausdorff-schools-2022/algorithmicdata2022/):

This Hausdorff School is intended for motivated graduate or postdoctoral students of mathematics or computer science. Leading experts discuss geometric and probabilistic approximation techniques and their connections to learning theory.

Dates: May 23–27; apply by March 27. A CV and Letter of Intent (1 page) are required, as well as the name and contact information of a potential reference.

#### [TUM AI - Lecture Series in 2022 ](https://twitter.com/MattNiessner/status/1482370056398979078)

Kicking off our TUM AI - Lecture Series in 2022 on Monday with no other than Jitendra Malik! He will be talking about "Learning to Walk With Vision and Proprioception".

#### [Talking Papers: UC-Net](https://twitter.com/talking_papers/status/1484284980704555008)

In this episode I had a chat with  Jing Zhang about UC-Net. If you are a student/researcher in #ComputerVision #ML #AI this is for you!!!

UC-Net proposes a probabilistic RGBD saliency detection network. They model the uncertainty in human annotation using a conditional variational autoencoder and generate multiple saliency maps for each input image by sampling the latent space.
****

### 成果推荐及讨论
**[Accelerate Implicit Neural leanring](https://twitter.com/mirror2mask/status/1482029174629879815?cxt=HHwWjsCiydTrnJEpAAAA)**: 
[Natalya Tatarchuk](https://twitter.com/mirror2mask)
If you haven't seen Instant Neural Graphics Primitives with a Multiresolution Hash Encoding 
[paper](https://nvlabs.github.io/instant)
-ngp/assets/mueller2022instant.pdf): take a look, truly groundbreaking work. This changes the equation for NERF rendering in a significant way.

![Selection_162](https://user-images.githubusercontent.com/39289436/149622369-61fcac49-a9aa-40ca-9609-d7407d9710a1.png)

**[ConvNet](https://github.com/facebookresearch/ConvNeXt)**:
Constructed entirely from standard ConvNet modules, achieving 87.8% ImageNet top-1 accuracy and outperforming **Swin Transformers(Best paper ICCV2021)** on COCO detection and ADE20K segmentation 

![Selection_163](https://user-images.githubusercontent.com/39289436/149622383-6026ffa8-d6b3-4b84-a153-f885d9db7eb4.png)

#### [ VERIV - Vscode Extended Range Imaging Viewer](https://twitter.com/mcrespo__/status/1483085482179366923)

How does it work? You only need to install it and open a compatible LDR or HDR file. 
The viewer will open automatically, allowing you to view the image, move it, zoom in and out, and adjust the exposure.

#### [data2vec from Meta AI](https://twitter.com/MetaAI/status/1484210570723307521)

The first general high-performance self-supervised algorithm for speech, vision, and text. When applied to different modalities, it matches or outperforms the best self-supervised algorithms.

#### [SAVi](https://twitter.com/thomaskipf/status/1463868218347556866)

Excited to share our work on Conditional Object-Centric Learning from Video! 

We introduce SAVi, a slot-based model that can discover + represent visual entities in videos, using simple location cues and object motion (...or entirely unsupervised).

#### [AI Draws Images](https://twitter.com/twominutepapers/status/1484195290999574530)

NVIDIA’s New AI Draws Images With The Speed of Thought! 



### 招聘
[虚拟人研究人员招聘 (Michael Black)组](https://twitter.com/Michael_J_Black/status/1470389393206747146)

[招实习生 SGI](https://twitter.com/JustinMSolomon/status/1478499442714054658)
