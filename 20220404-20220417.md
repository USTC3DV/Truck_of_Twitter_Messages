### æ„è§æ€§åˆ†äº«
#### å·¥å…·åˆ†äº«
- [Andrew White](https://twitter.com/andrewwhite01/status/1512494709721214982)

    - Do you like symmetry? Well check out our new python library to make your points symmetric. This is the Python tutorial for how we made Symmetric Molecular Dynamics 
    - [https://whitead.github.io/symd/Tutorial.html](https://whitead.github.io/symd/Tutorial.html)

- [Kosta Derpanis](https://twitter.com/CSProfKGD/status/1514229780488540162)
  - Please be mindful of your colour choices in plots for those that cannot differentiate them.  At the very least, use different symbols.
  - colorBlindness Guide: [https://cran.r-project.org/web/packages/colorBlindness/vignettes/colorBlindness.html](https://cran.r-project.org/web/packages/colorBlindness/vignettes/colorBlindness.html)
 
### è¯¾ç¨‹å’ŒæŠ¥å‘Šåˆ†äº«
- [Petar VeliÄkoviÄ‡](https://twitter.com/PetarV_93/status/1512468943461625864)

    - What happens when a top representation theorist (Geordie Williamson) covers geometric deep learning? IMHO, one of the most beautiful talks on the topic.
    - [https://www.youtube.com/watch?v=7pRIjJ_u2_c](https://www.youtube.com/watch?v=7pRIjJ_u2_c)

- [Matthias Niessner](https://twitter.com/MattNiessner/status/1513510343863058436)
  - Today in our TUM AI - Lecture Series in 2022 we will have Gordon Wetzstein @GordonWetzstein
 talking about "Efficient Neural Scene Representation, Rendering, and Generation"!
  - [https://www.youtube.com/watch?v=0KslwGsI9X8](https://www.youtube.com/watch?v=0KslwGsI9X8)

- [Erik Bekkers](https://twitter.com/erikjbekkers/status/1513748742805069832)
  - Lecture 2 is out!ğŸ¤“Steerable G-CNNs. I did my best to keep it as intuitive as possibl; went all out on colorful figs/gifs/eqs, even went through the hassle of rewriting harmonic nets @danielewworrall as regular G-CNNs to make a case!ğŸ˜…Hope y'all like it! 
  - [https://www.youtube.com/playlist?list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd](https://www.youtube.com/playlist?list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd)

- [Serge Belongie](https://twitter.com/SergeBelongie/status/1513613129124622343)
  - â€œToward Dense 3D Reconstruction in the Wildâ€ @JiaDeng @PrincetonCS seminar April 20 kl. 14.00 CET / 8am ET  @AiCentreDK #P1 More information and Zoom link: 
  - [https://di.ku.dk/begivenhedsmappe/begivenheder-2022/pioneer-centre-for-ai-virtual-seminar-jia-deng](https://di.ku.dk/begivenhedsmappe/begivenheder-2022/pioneer-centre-for-ai-virtual-seminar-jia-deng)

- [EveryPoint](https://twitter.com/EveryPointIO/status/1514348592965640194)
  - Want to see how NeRF's are made? Our very own,  @jonstephens85 presented a livestream hands on demo of Nvidia's Instant NeRF. The future is moving fast for #Computervision!
  - [https://www.youtube.com/watch?v=z3-fjYzd0BA&feature=youtu.be](https://www.youtube.com/watch?v=z3-fjYzd0BA&feature=youtu.be)
### æˆæœæ¨èåŠè®¨è®º
- [AK](https://twitter.com/ak92501/status/1512317805537939460)

    - SunStage: Portrait Reconstruction and Relighting using the Sun as a Light Stage
    - paper: [https://arxiv.org/abs/2204.03648](https://arxiv.org/abs/2204.03648)
    - project page: [https://grail.cs.washington.edu/projects/sunstage/](https://grail.cs.washington.edu/projects/sunstage/)


- [Andrew Davison](https://twitter.com/AjdDavison/status/1513448629079523328)
    - iSDF uses the main incremental neural field training methods of iMAP, but interprets the MLP output as a signed distance field rather than occupancy. Similar reconstruction quality, with auto hole-filling. Directly building an SDF could be useful for some robot planning cases.
    - paper: [https://arxiv.org/abs/2204.02296](https://arxiv.org/abs/2204.02296)
    - project page: [https://joeaortiz.github.io/iSDF/](https://joeaortiz.github.io/iSDF/)
  
- [Michael Black](https://twitter.com/Michael_J_Black/status/1514183295055060992)
  - IMavatar (#CVPR2022) learns implicit head avatars from monocular videos. It represents the expression and pose deformations via learned blendshapes and skinning fields. These are used to morph the canonical geometry and texture fields given novel expression and pose parameters.
  - IMavatars are learned end-to-end from video and provide fine-grain animation control using FLAME parameters. This produces implicit head avatars with more realistic shape (see the detailed normal maps) and appearance than the recent SOTA.
  - paper: [https://arxiv.org/abs/2112.07471](https://arxiv.org/abs/2112.07471)
  - project page: [https://ait.ethz.ch/projects/2022/IMavatar/](https://ait.ethz.ch/projects/2022/IMavatar/)

- [Matthias Niessner](https://twitter.com/MattNiessner/status/1513491475048419328)
  - Check out AutoRF: Learning 3D Object Radiance Fields from Single View Observations #CVPR2022 by @Normanisation. 
  - Key idea: we learn shape & appearance priors from single-view training samples by exploiting machine-annotated labels!
  - project page: [https://sirwyver.github.io/AutoRF/](https://sirwyver.github.io/AutoRF/)
  - video: [https://www.youtube.com/watch?v=mDcsSK3GaF4](https://www.youtube.com/watch?v=mDcsSK3GaF4)
  - comments:
    - question1: How does it figure out the homography, angle and probably rotation of the camera? What about places where the floor is on different heights through the scene?
    - reply1: We leverage off-the-shelf monocular 3D detections to calculate the relative pose of the camera. This way we can also support different floor levels

- [Hao Li](https://twitter.com/HaoLi81/status/1513766876593070083)
  - Our @fxguidenews article on @PinscreenInc's latest AI VFX pipeline for translating entire movies from any language to English using neural facial retargeting. In partnership with @Adapt_Films, @mikeseymour, we present the Champion of Auschwitz in English.
  - Our latest work featured in @TheWrap! In partnership with @Adapt_Films and @mikeseymour, @PinscreenInc
  demonstrates the first complete AI VFX pipeline that can translate an entire feature film in a foreign language to English using neural rendering tech:
  - project page: [https://www.fxguide.com/fxfeatured/the-neural-rendering-of-the-champion/](https://www.fxguide.com/fxfeatured/the-neural-rendering-of-the-champion/)

- [AK](https://twitter.com/ak92501/status/1514778958255984647)
  - Any-resolution Training for High-resolution Image Synthesis
  - paper: [https://arxiv.org/abs/2204.07156](https://arxiv.org/abs/2204.07156)
  - project page: [https://chail.github.io/anyres-gan/](https://chail.github.io/anyres-gan/)

- [Zhiqin Chen](https://twitter.com/ZhiqinChen3/status/1514313281254551552)
  - Pleased to announce our @NVIDIAAI #CVPR2022 paper AUV-Net! AUV-Net learns aligned UV maps for a set of 3D shapes, allowing us to easily transfer textures between 3D shapes by simply swapping their texture images.
  - project page: [https://nv-tlabs.github.io/AUV-NET/](https://nv-tlabs.github.io/AUV-NET/)

- [Marko Mihajlovic](https://twitter.com/marko_mih/status/1514509014616494080)
  - COAP: Compositional Articulated Occupancy of People
  - Our generalizable neural implicit body leverages a localized encoder-decoder to model volumetric humans #CVPR2022 
  - COAP is useful for resolving self-intersections and collisions with other objects 
  - paper: [https://arxiv.org/abs/2204.06184](https://arxiv.org/abs/2204.06184)
  - project page: [https://neuralbodies.github.io/COAP/](https://neuralbodies.github.io/COAP/)
  

### æ‹›è˜
- [Drew Jaegle](https://twitter.com/drew_jaegle/status/1513867248330547200) DeepMind
  - Iâ€™m hiring a Research Scientist to work on anymodal architectures and representation learning! If youâ€™re interested in building systems for all the worldâ€™s data ğŸ“·âš—ï¸ğŸ™ï¸ğŸ“šğŸ”¬, please apply to @DeepMind's RS London role and mention youâ€™d like to work with me.
